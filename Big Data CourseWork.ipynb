{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88b3d16a-8cce-4a6b-85d9-d95f48eb9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/tinkuacchu/anaconda3/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /Users/tinkuacchu/anaconda3/lib/python3.12/site-packages (from pyspark) (0.10.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f6ff39c-f241-4c4b-90f6-43c1f1a4035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, sum as spark_sum\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08869c9-00e1-4e87-bb7d-606f3257476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/14 22:48:28 WARN Utils: Your hostname, TinkuAcchus-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 10.133.144.3 instead (on interface en0)\n",
      "25/08/14 22:48:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/14 22:48:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"StudentsAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d0971d-b190-46e1-bdac-23afd015aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the dataset\n",
    "# 'inferSchema=True' automatically detects data types, which is helpful.\n",
    "studentsDF = spark.read.csv(\"Students.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ddc83c-827b-4f3b-8d2d-5e494a7188c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Schema:\n",
      "root\n",
      " |-- Student_Name: string (nullable = true)\n",
      " |-- College_Name: string (nullable = true)\n",
      " |-- Stream: string (nullable = true)\n",
      " |-- Year_of_Study: integer (nullable = true)\n",
      " |-- AI_Tools_Used: string (nullable = true)\n",
      " |-- Daily_Usage_Hours: double (nullable = true)\n",
      " |-- Use_Cases: string (nullable = true)\n",
      " |-- Trust_in_AI_Tools: integer (nullable = true)\n",
      " |-- Impact_on_Grades: integer (nullable = true)\n",
      " |-- Do_Professors_Allow_Use: string (nullable = true)\n",
      " |-- Preferred_AI_Tool: string (nullable = true)\n",
      " |-- Awareness_Level: integer (nullable = true)\n",
      " |-- Willing_to_Pay_for_Access: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Device_Used: string (nullable = true)\n",
      " |-- Internet_Access: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Display the schema and first 5 rows to verify the data is loaded correctly\n",
    "print(\"DataFrame Schema:\")\n",
    "studentsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b2dae2-b88c-40da-9fba-ccc4eac7ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the DataFrame:\n",
      "+------------+--------------------+-----------+-------------+-------------+-----------------+--------------------+-----------------+----------------+-----------------------+-----------------+---------------+-------------------------+-------------+-----------+---------------+\n",
      "|Student_Name|        College_Name|     Stream|Year_of_Study|AI_Tools_Used|Daily_Usage_Hours|           Use_Cases|Trust_in_AI_Tools|Impact_on_Grades|Do_Professors_Allow_Use|Preferred_AI_Tool|Awareness_Level|Willing_to_Pay_for_Access|        State|Device_Used|Internet_Access|\n",
      "+------------+--------------------+-----------+-------------+-------------+-----------------+--------------------+-----------------+----------------+-----------------------+-----------------+---------------+-------------------------+-------------+-----------+---------------+\n",
      "|       Aarav|Indian Institute ...|Engineering|            4|       Gemini|              0.9|Assignments, Codi...|                2|               2|                     No|          Copilot|              9|                      Yes|Uttar pradesh|     Mobile|           Poor|\n",
      "|      Vivaan|Government Ram Bh...|   Commerce|            2|      ChatGPT|              3.4| Learning new topics|                3|              -3|                    Yes|            Other|              6|                       No| Chhattisgarh|     Laptop|           Poor|\n",
      "|      Aditya|Dolphin PG Instit...|    Science|            2|      Copilot|              3.6|MCQ Practice, Pro...|                5|               0|                     No|           Gemini|              1|                       No|  Uttarakhand|     Tablet|           Poor|\n",
      "|      Vihaan|Shaheed Rajguru C...|       Arts|            2|      Copilot|              2.9|     Content Writing|                5|               2|                    Yes|           Gemini|              5|                       No|    Delhi ncr|     Laptop|           High|\n",
      "|       Arjun|Roorkee College o...|    Science|            1|       Gemini|              0.9|Doubt Solving, Re...|                1|               3|                    Yes|            Other|              8|                      Yes|  Uttarakhand|     Laptop|         Medium|\n",
      "+------------+--------------------+-----------+-------------+-------------+-----------------+--------------------+-----------------+----------------+-----------------------+-----------------+---------------+-------------------------+-------------+-----------+---------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
    "studentsDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b5d2e1-e346-4682-a95f-8c0966a5541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/14 22:48:35 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+-----------------+\n",
      "|summary| Daily_Usage_Hours| Trust_in_AI_Tools|    Impact_on_Grades|  Awareness_Level|\n",
      "+-------+------------------+------------------+--------------------+-----------------+\n",
      "|  count|              3614|              3614|                3614|             3614|\n",
      "|   mean|2.5596845600442664|3.0232429441062534|0.003320420586607637|5.828444936358605|\n",
      "| stddev|1.2133193874234915|1.4369339911635717|  2.3707064650348753|2.925480785216794|\n",
      "|    min|               0.5|                 1|                  -5|                1|\n",
      "|    max|               5.0|                 5|                   5|               10|\n",
      "+-------+------------------+------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for numeric columns\n",
    "studentsDF.describe([\"Daily_Usage_Hours\", \"Trust_in_AI_Tools\", \"Impact_on_Grades\", \"Awareness_Level\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cbcaba-adae-4ccd-ae46-00e358131c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       AI_Tools_Used|\n",
      "+--------------------+\n",
      "|                Bard|\n",
      "|    ChatGPT, Copilot|\n",
      "|             ChatGPT|\n",
      "|               Other|\n",
      "|              Gemini|\n",
      "|             Copilot|\n",
      "|              Claude|\n",
      "|ChatGPT, Gemini, ...|\n",
      "|  Gemini, Midjourney|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of unique values in a categorical column\n",
    "studentsDF.select(\"AI_Tools_Used\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce53f0a3-ce17-4daf-b283-768b343a41c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3614"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studentsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b946bd83-f263-46c6-a3c3-bbc348a9d8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in each column:\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for missing values in each column:\")\n",
    "# Get a list of all column names\n",
    "columns_to_check = studentsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f53fe0-cc10-454b-8f0a-9d8dca49105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Student_Name': 0 missing values\n",
      "Column 'College_Name': 0 missing values\n",
      "Column 'Stream': 0 missing values\n",
      "Column 'Year_of_Study': 0 missing values\n",
      "Column 'AI_Tools_Used': 0 missing values\n",
      "Column 'Daily_Usage_Hours': 0 missing values\n",
      "Column 'Use_Cases': 0 missing values\n",
      "Column 'Trust_in_AI_Tools': 0 missing values\n",
      "Column 'Impact_on_Grades': 0 missing values\n",
      "Column 'Do_Professors_Allow_Use': 0 missing values\n",
      "Column 'Preferred_AI_Tool': 0 missing values\n",
      "Column 'Awareness_Level': 0 missing values\n",
      "Column 'Willing_to_Pay_for_Access': 0 missing values\n",
      "Column 'State': 1614 missing values\n",
      "Column 'Device_Used': 0 missing values\n",
      "Column 'Internet_Access': 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Loop through each column and print the count of nulls\n",
    "for column_name in columns_to_check:\n",
    "    missing_count = studentsDF.filter(col(column_name).isNull()).count()\n",
    "    print(f\"Column '{column_name}': {missing_count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982d4b81-de8c-4fe5-97b7-f3e11e3d02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where 'State' is null, then group by state and count\n",
    "state_counts = studentsDF.dropna(subset=['State']).groupBy(\"State\").count()\n",
    "\n",
    "# Order the counts in descending order and get the first row\n",
    "mode_state = state_counts.orderBy(desc(\"count\")).first()[\"State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d949e663-ca3e-4f48-a66f-1b9254875433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mode (most frequent value) of the 'State' column is: Maharashtra\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mode (most frequent value) of the 'State' column is: {mode_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a17bbd6-4fae-4805-a37f-211ee2883a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing 'State' values with the calculated mode\n",
    "studentsDF_imputed = studentsDF.fillna(mode_state, subset=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eade6ec-5250-48f7-af3e-989a3efdc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows with a missing 'State' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are no longer any null values in the 'State' column\n",
    "print(\"Count of rows with a missing 'State' after imputation:\", df_imputed.filter(col(\"State\").isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1361fd58-7992-4c03-a624-99630702a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+-------------+-----------------+--------------------+-----------------+----------------+-----------------------+-----------------+---------------+-------------------------+-------------+-----------+---------------+\n",
      "|Student_Name|        College_Name|     Stream|Year_of_Study|AI_Tools_Used|Daily_Usage_Hours|           Use_Cases|Trust_in_AI_Tools|Impact_on_Grades|Do_Professors_Allow_Use|Preferred_AI_Tool|Awareness_Level|Willing_to_Pay_for_Access|        State|Device_Used|Internet_Access|\n",
      "+------------+--------------------+-----------+-------------+-------------+-----------------+--------------------+-----------------+----------------+-----------------------+-----------------+---------------+-------------------------+-------------+-----------+---------------+\n",
      "|       Aarav|Indian Institute ...|Engineering|            4|       Gemini|              0.9|Assignments, Codi...|                2|               2|                     No|          Copilot|              9|                      Yes|Uttar pradesh|     Mobile|           Poor|\n",
      "|      Vivaan|Government Ram Bh...|   Commerce|            2|      ChatGPT|              3.4| Learning new topics|                3|              -3|                    Yes|            Other|              6|                       No| Chhattisgarh|     Laptop|           Poor|\n",
      "|      Aditya|Dolphin PG Instit...|    Science|            2|      Copilot|              3.6|MCQ Practice, Pro...|                5|               0|                     No|           Gemini|              1|                       No|  Uttarakhand|     Tablet|           Poor|\n",
      "|      Vihaan|Shaheed Rajguru C...|       Arts|            2|      Copilot|              2.9|     Content Writing|                5|               2|                    Yes|           Gemini|              5|                       No|    Delhi ncr|     Laptop|           High|\n",
      "|       Arjun|Roorkee College o...|    Science|            1|       Gemini|              0.9|Doubt Solving, Re...|                1|               3|                    Yes|            Other|              8|                      Yes|  Uttarakhand|     Laptop|         Medium|\n",
      "+------------+--------------------+-----------+-------------+-------------+-----------------+--------------------+-----------------+----------------+-----------------------+-----------------+---------------+-------------------------+-------------+-----------+---------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "studentsDF_imputed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93334494-2ab6-4eee-a307-25860231cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Student dataFrame with additional numeric column:\n",
      "+-------------------------+----------------------+\n",
      "|Willing_to_Pay_for_Access|Willing_to_Pay_Numeric|\n",
      "+-------------------------+----------------------+\n",
      "|                      Yes|                     1|\n",
      "|                       No|                     0|\n",
      "|                       No|                     0|\n",
      "|                       No|                     0|\n",
      "|                      Yes|                     1|\n",
      "+-------------------------+----------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a new column to store the numeric representation\n",
    "studentsDF_encoded = studentsDF_imputed.withColumn('Willing_to_Pay_Numeric',\n",
    "                                   when(col('Willing_to_Pay_for_Access') == 'Yes', 1).otherwise(0))\n",
    "\n",
    "# Show the new column alongside the original\n",
    "print(\"\\n Student dataFrame with additional numeric column:\")\n",
    "studentsDF_encoded.select(\"Willing_to_Pay_for_Access\", \"Willing_to_Pay_Numeric\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd6c55aa-3752-4eaf-b30a-a8191ce9c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Index the 'Stream' column to a numeric representation\n",
    "indexer = StringIndexer(inputCol=\"Stream\", outputCol=\"Stream_Index\")\n",
    "studentDF_indexed = indexer.fit(studentsDF_encoded).transform(studentsDF_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "545328d3-f52a-4764-a9db-2d8e567ae205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the indexed column\n",
    "encoder = OneHotEncoder(inputCol=\"Stream_Index\", outputCol=\"Stream_Vector\")\n",
    "studentDF_encoded_final = encoder.fit(studentDF_indexed).transform(studentDF_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfbd572c-583c-48d4-92b3-9614e60ff37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student dataFrame with'Stream' column after encoding:\n",
      "+-----------+------------+-------------+\n",
      "|Stream     |Stream_Index|Stream_Vector|\n",
      "+-----------+------------+-------------+\n",
      "|Engineering|1.0         |(9,[1],[1.0])|\n",
      "|Commerce   |4.0         |(9,[4],[1.0])|\n",
      "|Science    |0.0         |(9,[0],[1.0])|\n",
      "|Arts       |2.0         |(9,[2],[1.0])|\n",
      "|Science    |0.0         |(9,[0],[1.0])|\n",
      "+-----------+------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Show the results to see the indexed and vectorized columns\n",
    "print(\"\\nStudent dataFrame with'Stream' column after encoding:\")\n",
    "studentDF_encoded_final.select(\"Stream\", \"Stream_Index\", \"Stream_Vector\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3ad7eee-766a-40a4-97ea-fdb55191660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame Schema with features column:\n",
      "root\n",
      " |-- Student_Name: string (nullable = true)\n",
      " |-- College_Name: string (nullable = true)\n",
      " |-- Stream: string (nullable = true)\n",
      " |-- Year_of_Study: integer (nullable = true)\n",
      " |-- AI_Tools_Used: string (nullable = true)\n",
      " |-- Daily_Usage_Hours: double (nullable = true)\n",
      " |-- Use_Cases: string (nullable = true)\n",
      " |-- Trust_in_AI_Tools: integer (nullable = true)\n",
      " |-- Impact_on_Grades: integer (nullable = true)\n",
      " |-- Do_Professors_Allow_Use: string (nullable = true)\n",
      " |-- Preferred_AI_Tool: string (nullable = true)\n",
      " |-- Awareness_Level: integer (nullable = true)\n",
      " |-- Willing_to_Pay_for_Access: string (nullable = true)\n",
      " |-- State: string (nullable = false)\n",
      " |-- Device_Used: string (nullable = true)\n",
      " |-- Internet_Access: string (nullable = true)\n",
      " |-- Willing_to_Pay_Numeric: integer (nullable = false)\n",
      " |-- Stream_Index: double (nullable = false)\n",
      " |-- Stream_Vector: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "\n",
      "Final DataFrame with assembled features:\n",
      "+--------------------------------------+-----------------+-------------+\n",
      "|features                              |Daily_Usage_Hours|Stream_Vector|\n",
      "+--------------------------------------+-----------------+-------------+\n",
      "|(13,[0,1,2,3,5],[2.0,2.0,9.0,1.0,1.0])|0.9              |(9,[1],[1.0])|\n",
      "|(13,[0,1,2,8],[3.0,-3.0,6.0,1.0])     |3.4              |(9,[4],[1.0])|\n",
      "|(13,[0,2,4],[5.0,1.0,1.0])            |3.6              |(9,[0],[1.0])|\n",
      "|(13,[0,1,2,6],[5.0,2.0,5.0,1.0])      |2.9              |(9,[2],[1.0])|\n",
      "|(13,[0,1,2,3,4],[1.0,3.0,8.0,1.0,1.0])|0.9              |(9,[0],[1.0])|\n",
      "+--------------------------------------+-----------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Define the columns you want to use as features.\n",
    "# Make sure to include both your original numerical columns and your new vectorized columns.\n",
    "feature_columns = ['Trust_in_AI_Tools', 'Impact_on_Grades', 'Awareness_Level', 'Willing_to_Pay_Numeric', 'Stream_Vector']\n",
    "\n",
    "# Assemble the features into a single vector column named 'features'\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "studentDF_final = assembler.transform(studentDF_encoded_final)\n",
    "\n",
    "# Display the final schema and a sample of the new 'features' vector\n",
    "print(\"\\nFinal DataFrame Schema with features column:\")\n",
    "studentDF_final.printSchema()\n",
    "\n",
    "print(\"\\nFinal DataFrame with assembled features:\")\n",
    "studentDF_final.select(\"features\", \"Daily_Usage_Hours\", \"Stream_Vector\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7d9ca80-559c-4616-b869-f45e54be1e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Count: 2586\n",
      "Test Data Count: 1028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and test sets\n",
    "# 70% for training, 30% for testing. 'seed' ensures reproducibility.\n",
    "(trainingData, testData) = studentDF_final.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(f\"Training Data Count: {trainingData.count()}\")\n",
    "print(f\"Test Data Count: {testData.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f00ddb3-3d69-42e3-9d78-405b3534bfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Linear Regression model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/14 22:56:10 WARN Instrumentation: [1ebfd524] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/08/14 22:56:10 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/08/14 22:56:10 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Linear Regression model\n",
    "# 'featuresCol' = input vector of features\n",
    "# 'labelCol' = target variable \n",
    "linearModel = LinearRegression(featuresCol=\"features\", labelCol=\"Daily_Usage_Hours\")\n",
    "\n",
    "# Train the model on the training data\n",
    "print(\"\\nTraining the Linear Regression model...\")\n",
    "linear_model = linearModel.fit(trainingData)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "def1c6b2-9143-48b6-9d03-bfcb23a6ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions (Actual vs. Predicted Daily_Usage_Hours):\n",
      "+-----------------+------------------+----------------------------------------+\n",
      "|Daily_Usage_Hours|prediction        |features                                |\n",
      "+-----------------+------------------+----------------------------------------+\n",
      "|4.8              |2.541356682907782 |(13,[0,1,2,3,7],[4.0,3.0,9.0,1.0,1.0])  |\n",
      "|4.2              |2.6884280545267325|(13,[0,1,2,3,8],[4.0,1.0,5.0,1.0,1.0])  |\n",
      "|1.7              |2.555942472226904 |(13,[0,1,2,3,11],[5.0,-2.0,5.0,1.0,1.0])|\n",
      "|2.3              |2.3600599881142275|(13,[0,1,2,7],[1.0,-3.0,3.0,1.0])       |\n",
      "|2.6              |2.7573612648205374|(13,[0,1,2,3],[2.0,2.0,3.0,1.0])        |\n",
      "+-----------------+------------------+----------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = linear_model.transform(testData)\n",
    "\n",
    "# Show a few predictions alongside the actual values and features\n",
    "print(\"\\nSample Predictions (Actual vs. Predicted Daily_Usage_Hours):\")\n",
    "predictions.select(\"Daily_Usage_Hours\", \"prediction\", \"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0ff0ff5-75d6-4417-9802-d99e844428cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 1.1903326191173762\n",
      "R-squared (R2) on test data: 0.02065071112641026\n",
      "\n",
      "Model Coefficients: [-0.01945369532242912,0.02121758925078574,0.006858351064513779,0.07120213886904463,0.019322244176239373,-0.3968857565942115,-0.04778160915454097,-0.23946488690576576,-0.02252493252718884,-0.22124195758726567,-0.30684406807703835,-0.0719040517522307,0.08615591020184102]\n",
      "Model Intercept: 2.6620562849012384\n"
     ]
    }
   ],
   "source": [
    "# Get model summary (for evaluation metrics)\n",
    "trainingSummary = linear_model.summary\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"\\nRoot Mean Squared Error (RMSE) on test data: {trainingSummary.rootMeanSquaredError}\")\n",
    "print(f\"R-squared (R2) on test data: {trainingSummary.r2}\")\n",
    "\n",
    "# You can also print the coefficients and intercept\n",
    "print(\"\\nModel Coefficients:\", linear_model.coefficients)\n",
    "print(\"Model Intercept:\", linear_model.intercept)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca50df49-2a6f-48c2-8a8d-26173c9ad78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Tree Regression (GBTRegressor) Results:\n",
      "Root Mean Squared Error (RMSE): 1.1906205709140807\n",
      "R-squared (R2): 0.07564059315875016\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GBT Regressor model.\n",
    "gbtModel = GBTRegressor(featuresCol=\"features\", labelCol=\"Daily_Usage_Hours\", maxIter=10)\n",
    "\n",
    "# Train the model on the training data.\n",
    "gbt_model = gbtModel.fit(trainingData)\n",
    "\n",
    "# Make predictions on the test data.\n",
    "gbt_predictions = gbt_model.transform(testData)\n",
    "\n",
    "# Evaluate the model using a RegressionEvaluator.\n",
    "evaluator = RegressionEvaluator(labelCol=\"Daily_Usage_Hours\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(gbt_predictions)\n",
    "r2 = evaluator.evaluate(gbt_predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "print(f\"Gradient-Boosted Tree Regression (GBTRegressor) Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bfcfcfc-febb-4edf-becd-99cdb8a656dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means (Clustering) Results:\n",
      "Silhouette Score: 0.4694151247218369\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the K-Means model. You must specify the number of clusters (e.g., k=3).\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3)\n",
    "\n",
    "# Train the model. Note that there is no label column.\n",
    "kmeans_model = kmeans.fit(studentDF_final)\n",
    "\n",
    "# Make predictions to see which cluster each student belongs to.\n",
    "kmeans_predictions = kmeans_model.transform(studentDF_final)\n",
    "\n",
    "# Evaluate the clustering quality using the Silhouette Score.\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette_score = evaluator.evaluate(kmeans_predictions)\n",
    "\n",
    "print(f\"K-Means (Clustering) Results:\")\n",
    "print(f\"Silhouette Score: {silhouette_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a795ef5-15e7-4786-9e78-15120ad52ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Random Forest model...\n",
      "Model training complete.\n",
      "\n",
      "Random Forest Regressor Results:\n",
      "Root Mean Squared Error (RMSE): 1.2131915421409605\n",
      "R-squared (R2): 0.0402616489762303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the Random Forest Regressor model\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"Daily_Usage_Hours\", numTrees=10)\n",
    "\n",
    "# Train the model on the training data\n",
    "print(\"Training the Random Forest model...\")\n",
    "rf_model = rf.fit(trainingData)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "rf_predictions = rf_model.transform(testData)\n",
    "\n",
    "# Evaluate the model using a RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Daily_Usage_Hours\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(rf_predictions)\n",
    "r2 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "print(f\"\\nRandom Forest Regressor Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e9c8419-efeb-4b94-bfc1-37c56ef8e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ======================\n",
    "# Collect metrics from all models\n",
    "# ======================\n",
    "results = []\n",
    "\n",
    "# Linear Regression\n",
    "results.append({\n",
    "    \"Model\": \"Linear Regression\",\n",
    "    \"RMSE\": trainingSummary.rootMeanSquaredError,\n",
    "    \"R2\": trainingSummary.r2\n",
    "})\n",
    "\n",
    "# Gradient Boosted Trees\n",
    "results.append({\n",
    "    \"Model\": \"Gradient-Boosted Trees\",\n",
    "    \"RMSE\": evaluator.evaluate(gbt_predictions),\n",
    "    \"R2\": evaluator.evaluate(gbt_predictions, {evaluator.metricName: \"r2\"})\n",
    "})\n",
    "\n",
    "# Random Forest\n",
    "results.append({\n",
    "    \"Model\": \"Random Forest\",\n",
    "    \"RMSE\": evaluator.evaluate(rf_predictions),\n",
    "    \"R2\": evaluator.evaluate(rf_predictions, {evaluator.metricName: \"r2\"})\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7ae4b91-03e9-40a8-b3a4-e10c24fde4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 252:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model metrics saved to: /Users/tinkuacchu/BigData/model_metrics\n",
      "+--------------------+-------------------+------------------+\n",
      "|               Model|                 R2|              RMSE|\n",
      "+--------------------+-------------------+------------------+\n",
      "|   Linear Regression|0.02065071112641026|1.1903326191173762|\n",
      "|Gradient-Boosted ...|0.07564059315875016|1.1906205709140807|\n",
      "|       Random Forest| 0.0402616489762303|1.2131915421409605|\n",
      "+--------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================\n",
    "# Convert to Spark DataFrame\n",
    "# ======================\n",
    "results_df = spark.createDataFrame(results)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_dir = os.path.join(os.getcwd(), \"model_metrics\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as CSV for Tableau\n",
    "results_df.coalesce(1) \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(output_dir)\n",
    "\n",
    "print(f\"✅ Model metrics saved to: {output_dir}\")\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f9a04-b4d8-4dfd-af42-ea261c2fa732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
